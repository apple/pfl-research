{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PFL research with FLAIR\n",
    "This tutorial demonstrates how to go beyond the basics of PFL, by implementing your own algorithm, postprocessors and aggregator for testing your own hypotheses.\n",
    "\n",
    "We demonstrate this using image classification on the [FLAIR](https://github.com/apple/ml-flair) dataset. This is a multiclass classification image dataset with both coarse-grained and fine-grained classes. The dataset is inherently split into real users, which are the photographers of the images. This notebook will use the 17 coarse-grained classes for multi-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.A (If on local Jupyter notebook) Install environment & `pfl`\n",
    "To run this notebook locally with Jupyter and installing from source, follow these prerequisite steps:\n",
    "\n",
    "1. Follow installation instructions at https://github.com/apple/pfl-research/blob/main/benchmarks/README.md#setup-environment\n",
    "2. Activate the environment created by Poetry from (1) and add it to the notebook:\n",
    "```\n",
    "poetry shell\n",
    "pip install jupyter\n",
    "python -m ipykernel install --name \"notebook-tutorial\"\n",
    "```\n",
    "4. Start the notebook:\n",
    "```\n",
    "python -m jupyter notebook\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Additional packages to run notebook\n",
    "!{sys.executable} -m pip install h5py matplotlib nest_asyncio pandas torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "If you installed the packages above, you need to restart the kernel of the notebook by clicking on \"Kernel -> Restart\"\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.B (If on Colab) Install environment & `pfl`\n",
    "If you're running this notebook on colab, simply clone the pfl-research repo to access the data download and preprocess script, and then install prerequisite packages into existing environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/apple/pfl-research.git\n",
    "import os\n",
    "# Set the working directory to same as if running locally.\n",
    "os.chdir('pfl-research/tutorials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# PyTorch should already be installed in colab\n",
    "!{sys.executable} -m pip install pfl\n",
    "# Additional packages to run notebook\n",
    "!{sys.executable} -m pip install h5py matplotlib nest_asyncio pandas torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preparing data for simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scripts `pfl-research/dataset/flair/download_dataset.py` and `pfl-research/dataset/flair/preprocess_dataset.py` can be used to download and preprocess the FLAIR dataset into a HDF5 file.\n",
    "For simplicity of running this notebook, we will download a tiny, already preprocessed, version of the FLAIR dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-07-19 16:32:48--  https://pfl-data.s3.us-east-2.amazonaws.com/flair/flair_federated_small.hdf5\n",
      "Resolving pfl-data.s3.us-east-2.amazonaws.com (pfl-data.s3.us-east-2.amazonaws.com)... 52.219.93.194, 52.219.102.194, 3.5.132.244, ...\n",
      "Connecting to pfl-data.s3.us-east-2.amazonaws.com (pfl-data.s3.us-east-2.amazonaws.com)|52.219.93.194|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 552428318 (527M) [binary/octet-stream]\n",
      "Saving to: ‘../benchmarks/data/flair_federated_small.hdf5’\n",
      "\n",
      "flair_federated_sma 100%[===================>] 526.84M  1.83MB/s    in 4m 35s  \n",
      "\n",
      "2024-07-19 16:37:24 (1.91 MB/s) - ‘../benchmarks/data/flair_federated_small.hdf5’ saved [552428318/552428318]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P ../benchmarks/data/ https://pfl-data.s3.us-east-2.amazonaws.com/flair/flair_federated_small.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Both Jupyter and `pfl` use async. `nest_asyncio` allows `pfl` to run inside the notebook \n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# append the root directory to your paths to be able to reach the examples.  \n",
    "sys.path.append('../benchmarks')\n",
    "torch.random.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# Always import the `pfl` model first before initializing any `pfl` components to let `pfl` know which Deep Learning framework you will use.\n",
    "from pfl.model.pytorch import PyTorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use helper functions from `pfl-research/dataset/flair/common.py` to load information about the data and labels from HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating user_num_images for train: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 312/312 [00:00<00:00, 8384.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Coarse grained classes in FLAIR:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'animal': 0,\n",
       " 'art': 1,\n",
       " 'celebration': 2,\n",
       " 'equipment': 3,\n",
       " 'fire': 4,\n",
       " 'food': 5,\n",
       " 'games': 6,\n",
       " 'interior_room': 7,\n",
       " 'light': 8,\n",
       " 'liquid': 9,\n",
       " 'material': 10,\n",
       " 'music': 11,\n",
       " 'outdoor': 12,\n",
       " 'plant': 13,\n",
       " 'recreation': 14,\n",
       " 'religion': 15,\n",
       " 'structure': 16}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'User dataset sizes statistics'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    312.0\n",
       "mean       7.0\n",
       "std        5.5\n",
       "min        1.0\n",
       "25%        2.0\n",
       "50%        6.0\n",
       "75%       11.0\n",
       "max       20.0\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dataset.flair.common import (get_multi_hot_targets, get_label_mapping, get_user_num_images)\n",
    "\n",
    "#hdf5_path = '../benchmarks/data/flair_federated.hdf5'\n",
    "hdf5_path = '../benchmarks/data/flair_federated_small.hdf5'\n",
    "# A dictionary mapping class name to an output index.\n",
    "classes = get_label_mapping(hdf5_path, use_fine_grained_labels=False)\n",
    "num_classes = len(classes)\n",
    "\n",
    "# A dictionary mapping each user id to number of images.\n",
    "user_num_images = get_user_num_images(hdf5_path, 'train')\n",
    "user_ids = sorted(list(user_num_images.keys()))\n",
    "\n",
    "display('Coarse grained classes in FLAIR:')\n",
    "display((classes))\n",
    "display('User dataset sizes statistics')\n",
    "display(pd.Series(user_num_images.values()).describe().apply(\"{0:.1f}\".format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Label distribution](./assets/label-dist-small.png)\n",
    "\n",
    "As displayed above, the label of each image is a multi-hot vector of 17 classes. The user dataset sizes can be seen to be right-skewed, with 50% of users having <= 11 images, but the mean number of images per user 67.6 images.\n",
    "\n",
    "Since the data is inherently split into real users, we need to use [FederatedDataset](https://apple.github.io/pfl-research/reference/data.html#pfl.data.federated_dataset.FederatedDataset), which requires a function for sampling user IDs.\n",
    "\n",
    "Firstly, we define a function which samples user IDs uniformly at random (with replacement for simplicity). In real federated learning, users aren't typically available on a uniformly random basis, but researchers commonly make this simplification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_sampler = lambda: user_ids[np.random.randint(0, len(user_ids))]\n",
    "print('sampled 10 users:', [user_sampler() for _ in range(10)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The federated dataset is initialized using the above sampling function and a function that returns the user's dataset given its ID as input, `make_dataset_fn(user_id)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.data.dataset import Dataset\n",
    "from pfl.data.federated_dataset import FederatedDataset\n",
    "# `pfl.internal.ops` contains useful helper functions for manipulating tensors.\n",
    "from pfl.internal.ops import pytorch_ops as ops\n",
    "\n",
    "def make_dataset_fn(user_id):\n",
    "    with h5py.File(hdf5_path, 'r') as h5:\n",
    "        inputs = (np.array(h5[f'/train/{user_id}/images']) - 128) / 255.\n",
    "        # Get multi-hot labels for user.\n",
    "        # The zip of `row_indices` and `col_indices` is the sparse matrix of labels for a user.\n",
    "        row_indices = np.array(h5[f'/train/{user_id}/labels_row'])        \n",
    "        col_indices = np.array(h5[f'/train/{user_id}/labels_col'])\n",
    "        # Convert to a dense matrix of labels.\n",
    "        targets = np.zeros((len(inputs), 17), dtype=np.float32)\n",
    "        targets[row_indices, col_indices] = 1\n",
    "\n",
    "    return Dataset((\n",
    "        ops.to_tensor(inputs), \n",
    "        ops.to_tensor(targets)), user_id=user_id)\n",
    "\n",
    "train_federated_dataset = FederatedDataset(make_dataset_fn, user_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When iterating through the federated dataset, a user dataset is sampled every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "user, seed = next(train_federated_dataset)\n",
    "print('User: {}\\nunique user seed: {}\\ndataset length: {}\\nfirst 10 images:'.format(user.user_id, seed, len(user)))\n",
    "fig, axes = plt.subplots(1,min(len(user),10),figsize=(20,12))\n",
    "for ax, image, label in itertools.islice(zip(axes, *user.raw_data),10):\n",
    "    ax.set_title('labels={}'.format(torch.nonzero(label).squeeze().tolist()))\n",
    "    ax.imshow((image.cpu().numpy()*255+128).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a central dataset for central evaluation using a helper function available in `pfl-research`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.flair.common import make_central_datasets\n",
    "inputs_all, targets_all = [], []\n",
    "with h5py.File(hdf5_path, 'r') as h5:\n",
    "    for user_id in h5[f'/val'].keys():\n",
    "        inputs = (np.array(h5[f'/val/{user_id}/images']) - 128) / 255.\n",
    "        # Get multi-hot labels for user.\n",
    "        row_indices = np.array(h5[f'/val/{user_id}/labels_row'])\n",
    "        col_indices = np.array(h5[f'/val/{user_id}/labels_col'])\n",
    "        targets = np.zeros((len(inputs), 17), dtype=np.float32)\n",
    "        targets[row_indices, col_indices] = 1\n",
    "        inputs_all.append(inputs)\n",
    "        targets_all.append(targets)\n",
    "\n",
    "inputs_all = np.vstack(inputs_all)\n",
    "targets_all = np.vstack(targets_all)\n",
    "data_tensors = [inputs_all, targets_all]\n",
    "central_data = Dataset(raw_data=data_tensors)\n",
    "print('data shape:', [t.shape for t in central_data.raw_data])\n",
    "print('fraction of positive labels:', central_data.raw_data[1].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As displayed above, the images are of dimensions `256x256` with `3` color channels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Defining the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a model in `pfl` is exactly the same as you would normally define a model for training. One of `pfl`’s strengths is that it is agnostic to any Deep Learning framework, which enables `pfl` to support multiple Deep Learning frameworks. \n",
    "\n",
    "Frameworks supported by `pfl` server-side are PyTorch and TensorFlow.\n",
    "`pfl` also support ML models like GBDTs which use numpy.\n",
    "\n",
    "We will define a PyTorch model in the exact same way as we would for regular centralized training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional\n",
    "from pfl.metrics import Weighted\n",
    "import torch\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "# Initialize model with pretrained weights.\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "pytorch_model = resnet18(weights=weights)\n",
    "\n",
    "# Modify final classification layer.\n",
    "num_ftrs = pytorch_model.fc.in_features\n",
    "pytorch_model.fc = torch.nn.Linear(num_ftrs, 17)\n",
    "\n",
    "# Freeze all layers.\n",
    "for param in pytorch_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Then unfreeze the last dense layer and final resnet block.\n",
    "for param in list(pytorch_model.fc.parameters()) + list(pytorch_model.layer4.parameters()):\n",
    "    param.requires_grad = True\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def loss(inputs: torch.Tensor, targets: torch.Tensor, eval: bool = False) -> torch.Tensor:\n",
    "    pytorch_model.eval() if eval else pytorch_model.train()\n",
    "    return loss_fn(pytorch_model(inputs.permute((0,3,1,2))), targets)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def metrics(inputs: torch.Tensor,\n",
    "             targets: torch.Tensor,\n",
    "             eval: bool = True) -> Dict[str, Weighted]:\n",
    "    pytorch_model.eval() if eval else pytorch_model.train()\n",
    "    logits = pytorch_model(inputs.permute((0,3,1,2)))\n",
    "    num_samples = len(inputs)\n",
    "    num_predictions = targets.numel()\n",
    "    correct = torch.sum(torch.eq((logits > 0.0).float(), targets))\n",
    "\n",
    "    loss = loss_fn(logits, targets).item()\n",
    "    return {\n",
    "        \"loss\": Weighted(loss, num_samples),\n",
    "        \"accuracy\": Weighted(correct, num_predictions)\n",
    "    }\n",
    "\n",
    "pytorch_model.loss = loss\n",
    "pytorch_model.metrics = metrics\n",
    "pytorch_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `pfl` `Model` acts as an adapter between the model defined using a Deep Learning framework and pfl. In this example, we use PyTorch to define our model, and so use `PyTorchModel` as the adapter.\n",
    "\n",
    "The central optimizer is an input parameter to the `pfl` `PyTorchModel` object. This optimizer is used when applying the aggregated model update to the central model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in pytorch_model.parameters() if p.requires_grad]\n",
    "\n",
    "model = PyTorchModel(pytorch_model, \n",
    "                     local_optimizer_create=torch.optim.SGD,\n",
    "                     central_optimizer=torch.optim.SGD(params, 1.0))\n",
    "\n",
    "# Save initial model\n",
    "model.save('tutorial_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a model using Private Federated Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Backend` is a component in `pfl` used to collect and aggregate statistics from user devices. [SimulatedBackend](https://apple.github.io/pfl-research/reference/aggregate.html#pfl.aggregate.SimulatedBackend) enables simulations to run for aggregating statistics from user devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.aggregate.simulate import SimulatedBackend\n",
    "\n",
    "cohort_size = 10\n",
    "central_num_iterations = 5\n",
    "\n",
    "# Instantiate simulated federated averaging\n",
    "simulated_backend = SimulatedBackend(\n",
    "    training_data=train_federated_dataset,\n",
    "    val_data=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main component of a `pfl` modeling setup is the algorithm. In this tutorial, we will be using the [Federated Averaging](https://arxiv.org/pdf/1602.05629.pdf) algorithm. `pfl` implements Federated Averaging using the class [FederatedAveraging](https://apple.github.io/pfl-research/reference/algorithm.html#pfl.algorithm.federated_averaging.FederatedAveraging).\n",
    "\n",
    "Everything is tied together in the `run` method of an algorithm. This method requires the model, backend, optional callbacks, as well as hyperparameters, which depend on the model and algorithm, and are respectively defined using `NNTrainHyperParams` and `NNAlgorithmParams` objects.\n",
    "\n",
    "Hyperparameters regarding local training commonly have a prefix `local_` and hyperparameters regarding central updates commonly have a prefix `central_`. Important hyperparameters for federated learning include `local_learning_rate` and `local_num_epochs` which respectively specify the learning rate and the number of training epochs to be used for local training on devices during federated averaging. These hyperparameters differ to `central_learning_rate` and `central_num_iterations` which apply to training the central model using aggregated updates from devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.algorithm import FederatedAveraging, NNAlgorithmParams\n",
    "from pfl.callback import CentralEvaluationCallback\n",
    "from pfl.hyperparam import NNTrainHyperParams, NNEvalHyperParams\n",
    "\n",
    "model_train_params = NNTrainHyperParams(\n",
    "    local_learning_rate=0.01,\n",
    "    local_num_epochs=2,\n",
    "    local_batch_size=16)\n",
    "\n",
    "model_eval_params = NNEvalHyperParams(local_batch_size=20)\n",
    "\n",
    "algorithm_params = NNAlgorithmParams(\n",
    "    central_num_iterations=central_num_iterations,\n",
    "    evaluation_frequency=4,\n",
    "    train_cohort_size=cohort_size,\n",
    "    val_cohort_size=0)\n",
    "\n",
    "callbacks = [\n",
    "    CentralEvaluationCallback(\n",
    "        central_data,\n",
    "        model_eval_params=model_eval_params,\n",
    "        frequency=4),\n",
    "]\n",
    "\n",
    "model = FederatedAveraging().run(\n",
    "    algorithm_params=algorithm_params,\n",
    "    backend=simulated_backend,\n",
    "    model=model,\n",
    "    model_train_params=model_train_params,\n",
    "    model_eval_params=model_eval_params,\n",
    "    callbacks=callbacks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Defining a custom algorithm\n",
    "`pfl` has excellent interfaces for implementing your own research ideas.\n",
    "Extend the algorithm class when you want to test ideas related to the local training procedure or how the aggregated statistics are handled and applied to the central model. There are 3 base classes you can subclass to make your algorithm:\n",
    "* [FederatedAlgorithm](https://apple.github.io/pfl-research/reference/algorithm.html#pfl.algorithm.base.FederatedAlgorithm)\n",
    "* [FederatedNNAlgorithm](https://apple.github.io/pfl-research/reference/algorithm.html#pfl.algorithm.base.FederatedNNAlgorithm)\n",
    "* [PersonalizedNNAlgorithmParams](https://apple.github.io/pfl-research/reference/algorithm.html#pfl.algorithm.base.PersonalizedNNAlgorithmParams)\n",
    "\n",
    "See respective reference for when each interface is appropriate to use. In the case of training a nerual network model with Federated Learning, it is easiest to use [FederatedNNAlgorithm](https://apple.github.io/pfl-research/reference/algorithm.html#pfl.algorithm.base.FederatedNNAlgorithm). Below is an example of a custom algorithm class that reimplements Federated Averaging using PyTorch operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.algorithm.base import FederatedNNAlgorithm\n",
    "from pfl.metrics import Metrics\n",
    "\n",
    "central_opt = torch.optim.Adam([p for p in pytorch_model.parameters() if p.requires_grad], lr=1.0)\n",
    "        \n",
    "class MyAlgorithm(FederatedNNAlgorithm):\n",
    "        \n",
    "    def process_aggregated_statistics(self, central_context, aggregate_metrics, model, stats):\n",
    "        stats.average()\n",
    "        \n",
    "        # Below is equivalent to \n",
    "        # return model.apply_model_update(statistics)\n",
    "        central_opt.zero_grad()\n",
    "        for name, var in model.pytorch_model.named_parameters():\n",
    "            if not var.requires_grad:\n",
    "                # Frozen variable\n",
    "                continue\n",
    "            if var.grad is None:\n",
    "                var.grad = torch.zeros_like(var)\n",
    "            var.grad.data.copy_(-1*stats[name])\n",
    "        central_opt.step()\n",
    "        \n",
    "        return model, Metrics([('I updated it', 1.0)])\n",
    "\n",
    "    \n",
    "    def train_one_user(self, initial_state, model, user_dataset, central_context):\n",
    "        opt = torch.optim.SGD(model.pytorch_model.parameters(), lr=0.1)\n",
    "        opt.zero_grad()\n",
    "        for x, y in user_dataset.iter(5):\n",
    "            model.pytorch_model.loss(x, y).backward()\n",
    "            opt.step()\n",
    "        return model.get_model_difference(initial_state), Metrics([('I trained it', 1.0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when running the custom algorithm, we will see the two new metrics `I updated it` and `I trained it` emitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset from initial weights\n",
    "model.load('tutorial_model')\n",
    "\n",
    "model = MyAlgorithm().run(\n",
    "    algorithm_params=algorithm_params,\n",
    "    backend=simulated_backend,\n",
    "    model=model,\n",
    "    model_train_params=model_train_params,\n",
    "    model_eval_params=model_eval_params,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defining a dynamic hyperparameter\n",
    "The Federated Learning training paradigm often adds many more hyperparameters to tune. Therefore, it can be a good idea to make hyperparameters dynamic and more intelligent. In `pfl`'s library of algorithms and models, many of the hyperparameters are allowed to be dynamic in the form of a [HyperParam](https://apple.github.io/pfl-research/reference/hyperparam.html#pfl.hyperparam.base.HyperParam). It is a base class with a single method `value()`, where concrete implementations should return the value of the hyperparameter at that point in time.\n",
    "\n",
    "To dynamically change the value during training, the concrete subclass implementation can also extend one of the two different hooks that `pfl` calls into during training:\n",
    "* [Callback](https://apple.github.io/pfl-research/reference/callback.html#pfl.callback.TrainingProcessCallback) - has one hook for each of: before training begins; at the end of each central iteration; and after all central iterations of training have ended.\n",
    "* [Postprocessor](https://apple.github.io/pfl-research/reference/postprocessor.html#pfl.postprocessor.Postprocessor) - has one hook at the postprocessing stage of an individual user and one hook at the postprocessing stage of the aggregated model update, before it is sent to the algorithm.\n",
    "\n",
    "Here is an example of a local learning rate warmup implementation. We extend `TrainingProcessCallback`, but `Postprocessor.postprocess_server` could have worked equally well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.hyperparam import HyperParam\n",
    "from pfl.callback import TrainingProcessCallback\n",
    "\n",
    "class LocalLRWarmup(HyperParam, TrainingProcessCallback):\n",
    "    def __init__(self, initial_value: float, max_value: float):\n",
    "        self._value = initial_value\n",
    "        self._max_value = max_value\n",
    "      \n",
    "    def value(self):\n",
    "        return self._value\n",
    "\n",
    "    def after_central_iteration(self, aggregate_metrics, model, central_iteration):\n",
    "        self._value = min(self._value*5, self._max_value)\n",
    "        return False, Metrics([('dynamic local lr', self._value)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add an instance of `LocalLRWarmup` as the actual argument to `local_learning_rate`. Also make sure to add the same instance as one of the callbacks in `run` such that updating the internal value is actually triggered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset from initial weights\n",
    "model.load('tutorial_model')\n",
    "\n",
    "local_lr = LocalLRWarmup(0.0001, 0.1)\n",
    "\n",
    "simulated_backend = SimulatedBackend(\n",
    "    training_data=train_federated_dataset,\n",
    "    val_data=None)\n",
    "\n",
    "model_train_params = NNTrainHyperParams(\n",
    "    local_learning_rate=local_lr,\n",
    "    local_num_epochs=2,\n",
    "    local_batch_size=5)\n",
    "\n",
    "model = MyAlgorithm().run(\n",
    "    algorithm_params=algorithm_params,\n",
    "    backend=simulated_backend,\n",
    "    model=model,\n",
    "    model_train_params=model_train_params,\n",
    "    model_eval_params=model_eval_params,\n",
    "    callbacks=callbacks + [local_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Defining a custom postprocessor\n",
    "Assuming aggregation is a black box that securely aggregates the user payloads without being able to inspect each payload individually on the server, there are ideas that can improve the overall practical Federated Learning experience by manipulating the payload before communication and after aggregation. This concept is called [Postprocessor](https://apple.github.io/pfl-research/reference/postprocessor.html#pfl.postprocessor.Postprocessor) in `pfl` and is orthogonal to a `Model`, `Algorithm` and `Aggregator`. Some categories of research that may be expressed as a `Postprocessor` are (but not limited to):\n",
    "* [Privacy mechanisms](https://apple.github.io/pfl-research/reference/privacy.html)\n",
    "* Quantization\n",
    "* Sparsification\n",
    "* Weighting\n",
    "\n",
    "Below we implement top-K sparsification as a `Postprocessor`, which will zero out `1-top_k_percent` percent of the model update elements with the lowest absolute values, making the model update sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from pfl.context import CentralContext, UserContext\n",
    "from pfl.postprocessor import Postprocessor\n",
    "from pfl.stats import TrainingStatistics\n",
    "\n",
    "class SparsifyTopK(Postprocessor):\n",
    "    def __init__(self, top_k_percent: int = 0.1):\n",
    "        self._top_k_percent = top_k_percent\n",
    "        \n",
    "    def postprocess_one_user(self, stats: TrainingStatistics, user_context: UserContext) -> Tuple[TrainingStatistics, Metrics]:\n",
    "        # Flatten to vector\n",
    "        metadata, weights = stats.get_weights()\n",
    "        vector, shapes, types = ops.flatten(weights)\n",
    "\n",
    "        # Mask topK\n",
    "        num_top_elements = int(self._top_k_percent * len(vector))\n",
    "        _, indices = torch.topk(vector.abs(), num_top_elements)\n",
    "        mask = torch.zeros(len(vector), dtype=torch.bool, device=ops.get_default_device())\n",
    "        mask[indices] = 1\n",
    "        sparse_vector = vector * mask\n",
    "        actual_sparsity = (sparse_vector == 0).sum() / len(sparse_vector)\n",
    "\n",
    "        # Reshape sparse vector to weights of correct shapes\n",
    "        sparse_weights = ops.reshape(sparse_vector, shapes, types)\n",
    "        sparse_stats = stats.from_weights(metadata, sparse_weights)\n",
    "        \n",
    "        return sparse_stats, Metrics([('sparsity', Weighted.from_unweighted(actual_sparsity))])\n",
    "\n",
    "    def postprocess_server(self, *, stats: TrainingStatistics, \n",
    "                           central_context: CentralContext,\n",
    "                           aggregate_metrics: Metrics) -> Tuple[TrainingStatistics, Metrics]:\n",
    "        return stats, Metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can input `SparsifyTopK` as one of the postprocessors and re-run the algorithm. The new `sparsity` metric measures the actual sparsity in the user payload, which should match `1-top_k_percent`.\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "This kind of sparsification algorithm is commonly exercised in Federated Learning research litterature, but it is actually not compatible with Differential Privacy! Do you notice why?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset from initial weights\n",
    "model.load('tutorial_model')\n",
    "\n",
    "simulated_backend = SimulatedBackend(\n",
    "    training_data=train_federated_dataset,\n",
    "    val_data=None,\n",
    "    postprocessors=[\n",
    "        SparsifyTopK(0.5),\n",
    "    ])\n",
    "\n",
    "model_train_params = NNTrainHyperParams(\n",
    "    local_learning_rate=0.5,\n",
    "    local_num_epochs=2,\n",
    "    local_batch_size=5)\n",
    "\n",
    "model = MyAlgorithm().run(\n",
    "    algorithm_params=algorithm_params,\n",
    "    backend=simulated_backend,\n",
    "    model=model,\n",
    "    model_train_params=model_train_params,\n",
    "    model_eval_params=model_eval_params,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Defining a custom aggregator\n",
    "It is also possible to define your own aggregation scheme in `pfl`. [Aggregator](https://apple.github.io/pfl-research/reference/aggregate.html#pfl.aggregate.base.Aggregator) is an interface which lets you define how a model update from the user should be combined with the current accumulated statistics. If you want the aggregator to be compatible with distributed simulations you also need to implement `Aggregator.worker_reduce`.\n",
    "\n",
    "In the example below, we define a custom aggregator that combines two model updates by, for each element, selecting the value of the highest magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pfl.aggregate.base import Aggregator\n",
    "from pfl.stats import TrainingStatistics\n",
    "\n",
    "class MaxMagAggregator(Aggregator):\n",
    "    def accumulate(self, accumulated: Optional[TrainingStatistics], user_stats: TrainingStatistics) -> TrainingStatistics:\n",
    "        if accumulated is None:\n",
    "            # For the first statistics, simply return it.\n",
    "            return user_stats\n",
    "\n",
    "        for name in accumulated.keys():\n",
    "            accumulated_weight = accumulated[name]\n",
    "            user_weight = user_stats[name]\n",
    "            accumulated[name] = torch.where(\n",
    "                torch.abs(accumulated_weight) > torch.abs(user_weight), \n",
    "                accumulated_weight, \n",
    "                user_weight)\n",
    "        # Statistics might have a custom weight from the algorithm or other postprocessor.\n",
    "        # Reset it to 1 because we are not doing any weighted aggregation here.\n",
    "        accumulated.weight = 1\n",
    "        return accumulated\n",
    "\n",
    "    def worker_reduce(self, \n",
    "        aggregated_worker_stats: TrainingStatistics,\n",
    "        central_context: CentralContext, \n",
    "        aggregated_worker_metrics: Metrics) -> Tuple[TrainingStatistics, Metrics]:\n",
    "        \"\"\"\n",
    "        User statistics and metrics are first summed on each worker process,\n",
    "        then they are reduced across workers using this method.\n",
    "        This method can be ignored in concrete aggregator classes if it is\n",
    "        not compatible with multi-process training.\n",
    "\n",
    "        In the case of this example, we don't need it.\n",
    "        \n",
    "        TODO: actually show how it would look like to support distributed\n",
    "        simulations for this class.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SimulatedBackend` has an optional argument `aggregator` where we will input `MaxMagAggregator` to override the default aggregation scheme (which is summing in `accumulate` and all-reduce sum in `worker_reduce`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset from initial weights\n",
    "model.load('tutorial_model')\n",
    "\n",
    "simulated_backend = SimulatedBackend(\n",
    "    training_data=train_federated_dataset,\n",
    "    val_data=None,\n",
    "    aggregator=MaxMagAggregator())\n",
    "\n",
    "model = MyAlgorithm().run(\n",
    "    algorithm_params=algorithm_params,\n",
    "    backend=simulated_backend,\n",
    "    model=model,\n",
    "    model_train_params=model_train_params,\n",
    "    model_eval_params=model_eval_params,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfl-benchmarks",
   "language": "python",
   "name": "pfl-benchmarks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
